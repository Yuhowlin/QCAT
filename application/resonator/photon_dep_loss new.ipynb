{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import package and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from qcat.utility.file_structure import *\n",
    "from qcat.utility.io_translator import *\n",
    "# from analysis.analysis_method import *\n",
    "from qcat.visualization.photon_dep_loss import * \n",
    "\n",
    "root_fd = r\"D:\\Data\\resonator\\Res_v2_abd_0920\"\n",
    "raw_data_fd = f\"{root_fd}\\\\raw\"\n",
    "preprocess_data_fd = f\"{root_fd}\\\\preprocess\"\n",
    "plot_data_fd = f\"{root_fd}\\\\result\"\n",
    "output_fd = f\"{root_fd}\\\\result\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format convert ( LiteVNA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcat.utility.file_structure import create_subfolder\n",
    "\n",
    "\n",
    "# Get all resonator from folder\n",
    "resonator_list = [d for d in os.listdir(raw_data_fd) if os.path.isdir(os.path.join(raw_data_fd, d))]\n",
    "\n",
    "print(resonator_list)\n",
    "\n",
    "for resonator_label in resonator_list:\n",
    "\n",
    "    print(f\"{resonator_label}\")\n",
    "    resonator_fd = f\"{raw_data_fd}\\\\{resonator_label}\"\n",
    "    power_list = [d for d in os.listdir(resonator_fd) if os.path.isdir(os.path.join(resonator_fd, d))]\n",
    "\n",
    "    create_subfolder(preprocess_data_fd,resonator_label)\n",
    "    ave_resonator_folder = f\"{preprocess_data_fd}\\\\{resonator_label}\" \n",
    "\n",
    "    for power_label in power_list:\n",
    "\n",
    "        # print(f\"{resonator_label} {power_label}\")\n",
    "\n",
    "        power_fd = f\"{resonator_fd}\\\\{power_label}\"\n",
    "        file_list = [d for d in os.listdir(power_fd) ]\n",
    "        file_number = len(file_list)\n",
    "        print( f\"{file_number} files in {power_label}\" )\n",
    "        \n",
    "        same_power_data = []\n",
    "        \n",
    "        for i, f_name in enumerate(file_list):\n",
    "\n",
    "            # Read data\n",
    "            # print(f\"{i+1}/{file_number} {f_name}\")\n",
    "            file_fullpath = f\"{power_fd}\\\\{f_name}\"\n",
    "            dataset = xr.open_dataset(file_fullpath)\n",
    "\n",
    "            # Parse the time strings back to datetime objects\n",
    "            start_time = datetime.strptime(dataset.attrs[\"start_time\"], \"%Y%m%d_%H%M%S\")\n",
    "            end_time = datetime.strptime(dataset.attrs[\"end_time\"], \"%Y%m%d_%H%M%S\")\n",
    "            if i==0: \n",
    "                start_time_all = start_time\n",
    "                end_time_all = end_time\n",
    "            if start_time < start_time_all : start_time_all = start_time\n",
    "            if end_time > end_time_all : end_time_all = end_time_all\n",
    "\n",
    "\n",
    "            power = dataset.attrs[\"power\"]\n",
    "            attenuation = dataset.attrs[\"attenuation\"]\n",
    "            # attenuation = 105\n",
    "\n",
    "            frequency = dataset.coords[\"frequency\"]\n",
    "            same_power_data.append(dataset[\"s21\"].values)\n",
    "\n",
    "        # print(same_power_data)\n",
    "        same_power_data = np.array(same_power_data)\n",
    "        print(same_power_data.ndim)\n",
    "        if same_power_data.ndim == 3:\n",
    "            ave_data = np.mean( np.array(same_power_data), axis=0 )\n",
    "        else:\n",
    "            ave_data = same_power_data\n",
    "        # print(ave_data)\n",
    "        # Creating an xarray dataset\n",
    "        output_data = {\n",
    "            \"s21\": ( [\"s_params\",\"frequency\"],\n",
    "                    np.array([ave_data[0], ave_data[1]]) )\n",
    "        }\n",
    "        dataset = xr.Dataset(\n",
    "            output_data,\n",
    "            coords={ \"s_params\":np.array([\"real\",\"imag\"]), \"frequency\": frequency })\n",
    "\n",
    "        dataset.attrs[\"power\"] = power\n",
    "        dataset.attrs[\"attenuation\"] = int(attenuation)\n",
    "        dataset.attrs[\"start_time\"] = str(start_time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "        dataset.attrs[\"end_time\"] = str(end_time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "        # print(dataset)\n",
    "        dataset.to_netcdf(f\"{ave_resonator_folder}\\\\liteVNA_{str(attenuation)}_{str(power)}.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format convert ( QM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcat.utility.file_structure import create_subfolder\n",
    "\n",
    "\n",
    "raw_data_fd = r\"d:\\Data\\resonator\\5Q4C\"\n",
    "preprocess_data_fd = r\"d:\\Data\\resonator\\5Q4C\\fit_data_pd\\q4_min\"\n",
    "# Get all resonator from folder\n",
    "# resonator_list = [d for d in os.listdir(raw_data_fd) if os.path.isdir(os.path.join(raw_data_fd, d))]\n",
    "\n",
    "f_name = \"20240626_1504_power_dep_resonator_q4_ro_min.nc\"\n",
    "freq_ref = 5900 -166.6+10+1.36-1.11+1.49-3.38\n",
    "ro_name = \"q4_ro\"\n",
    "\n",
    "# Read data\n",
    "# print(f\"{i+1}/{file_number} {f_name}\")\n",
    "file_fullpath = f\"{raw_data_fd}\\\\{f_name}\"\n",
    "dataset = xr.open_dataset(file_fullpath)\n",
    "# dataset = dataset.transpose( \"amp_ratio\", \"mixer\", \"frequency\" )\n",
    "print( dataset )\n",
    "# Parse the time strings back to datetime objects\n",
    "start_time = datetime.strptime(dataset.attrs[\"start_time\"], \"%Y%m%d_%H%M%S\")\n",
    "end_time = datetime.strptime(dataset.attrs[\"end_time\"], \"%Y%m%d_%H%M%S\")\n",
    "amp_ratio = dataset.coords[\"amp_ratio\"].values\n",
    "print(amp_ratio)\n",
    "power_list = 0 +20*np.log10(amp_ratio)\n",
    "attenuation = 0\n",
    "print(power_list)\n",
    "ave_data = dataset[ro_name].values\n",
    "\n",
    "frequency = (dataset.coords[\"frequency\"].values +freq_ref)*1e6\n",
    "print( frequency )\n",
    "\n",
    "temp_idx = ( 100, -100 )\n",
    "for i, power_label in enumerate(power_list):\n",
    "\n",
    "    print(power_label)\n",
    "    # Creating an xarray dataset\n",
    "    output_data = {\n",
    "        \"s21\": ( [\"s_params\",\"frequency\"],\n",
    "                np.array([ave_data[0][i][temp_idx[0]:temp_idx[1]], ave_data[1][i][temp_idx[0]:temp_idx[1]]]) )\n",
    "    }\n",
    "    output_dataset = xr.Dataset(\n",
    "        output_data,\n",
    "        coords={ \"s_params\":np.array([\"real\",\"imag\"]), \"frequency\": frequency[temp_idx[0]:temp_idx[1]] })\n",
    "\n",
    "    output_dataset.attrs[\"power\"] = power_label\n",
    "    output_dataset.attrs[\"attenuation\"] = int(attenuation)\n",
    "    output_dataset.attrs[\"start_time\"] = str(start_time.strftime(\"%m%d_%H%M%S\"))\n",
    "    output_dataset.attrs[\"end_time\"] = str(end_time.strftime(\"%m%d_%H%M%S\"))\n",
    "    # print(dataset)\n",
    "    output_dataset.to_netcdf(f\"{preprocess_data_fd}\\\\QM_{str(attenuation)}_{power_label:.1f}.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format convert ( PYQUM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcat.utility.file_structure import create_subfolder\n",
    "\n",
    "\n",
    "raw_data_fd = r\"D:\\Data\\resonator\\ITRI_364_scalinQ\\raw\"\n",
    "preprocess_data_fd = r\"d:\\Data\\resonator\\ITRI_364_scalinQ_new\\fit_data_pd\"\n",
    "# Get all resonator from folder\n",
    "resonator_list = [d for d in os.listdir(raw_data_fd) if os.path.isdir(os.path.join(raw_data_fd, d))]\n",
    "\n",
    "print(resonator_list)\n",
    "\n",
    "for resonator_label in resonator_list:\n",
    "\n",
    "    print(f\"{resonator_label}\")\n",
    "    resonator_fd = f\"{raw_data_fd}\\\\{resonator_label}\"\n",
    "    power_list = [d for d in os.listdir(resonator_fd) if os.path.isdir(os.path.join(resonator_fd, d))]\n",
    "\n",
    "    create_subfolder(preprocess_data_fd,resonator_label)\n",
    "    ave_resonator_folder = f\"{preprocess_data_fd}\\\\{resonator_label}\" \n",
    "\n",
    "    mat_files = check_file_extension( resonator_fd, \"mat\")\n",
    "    df_config = pd.read_json(f'{resonator_fd}\\\\config.json')\n",
    "    for index, row in df_config.iterrows():\n",
    "        attenuation = row[\"attenuation\"]\n",
    "        file_name = row[\"file_name\"]\n",
    "        print(f\"{file_name} with {attenuation} dB attenuation\")\n",
    "        power_list, frequency, s21 = mat_to_numpy(f\"{resonator_fd}\\\\{file_name}\")\n",
    "        print(frequency[0])\n",
    "        zdata_2d = s21.transpose()\n",
    "        for i, power_label in enumerate(power_list):\n",
    "            # print(power_label)\n",
    "            data = zdata_2d[i]\n",
    "\n",
    "\n",
    "            # Creating an xarray dataset\n",
    "            output_data = {\n",
    "                \"s21\": ( [\"s_params\",\"frequency\"],\n",
    "                        np.array([data.real, data.imag]) )\n",
    "            }\n",
    "            dataset = xr.Dataset(\n",
    "                output_data,\n",
    "                coords={ \"s_params\":np.array([\"real\",\"imag\"]), \"frequency\": frequency*1e9 })\n",
    "            \n",
    "            dataset.attrs[\"attenuation\"] = int(attenuation)\n",
    "            dataset.attrs[\"power\"] = power_label\n",
    "            dataset.to_netcdf(f\"{ave_resonator_folder}\\\\PYQUM_{str(attenuation)}_{str(power_label)}.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcat.analysis.resonator.photon_dep.res_data import *\n",
    "from qcat.utility.file_structure import check_file_extension, create_subfolder\n",
    "\n",
    "\n",
    "# Get all resonator from folder\n",
    "resonator_list = [d for d in os.listdir(preprocess_data_fd) if os.path.isdir(os.path.join(preprocess_data_fd, d))]\n",
    "# check_configure(f\"{output_fd}\", [\"power_dep_fit\"])\n",
    "# resonator_list = [\"C48398\"]\n",
    "all_resonator_result = []\n",
    "\n",
    "for resonator_label in resonator_list:\n",
    "    print(f\"Processing {resonator_label}\")\n",
    "\n",
    "    create_subfolder(output_fd,resonator_label)\n",
    "    result_folder = f\"{output_fd}\\\\{resonator_label}\"\n",
    "\n",
    "    resonator_data_folder = f\"{preprocess_data_fd}\\\\{resonator_label}\"\n",
    "    resonator = PhotonDepResonator(resonator_label)\n",
    "    # Find cavity data (nc file) in the folder\n",
    "    file_list = check_file_extension( resonator_data_folder, \"nc\")\n",
    "    print(resonator_data_folder)\n",
    "    print(file_list)\n",
    "    # file_list = ['liteVNA_80_-15.0.nc', 'liteVNA_80_-20.0.nc', 'liteVNA_80_-25.0.nc', 'liteVNA_80_-30.0.nc', 'liteVNA_80_-35.0.nc', 'liteVNA_80_-40.0.nc', 'liteVNA_80_-45.0.nc', 'liteVNA_80_-50.0.nc', 'liteVNA_80_-55.0.nc', 'liteVNA_80_-60.0.nc','liteVNA_110_-30.0.nc', 'liteVNA_110_-35.0.nc', 'liteVNA_110_-40.0.nc', 'liteVNA_110_-41.0.nc', 'liteVNA_110_-42.0.nc', 'liteVNA_110_-43.0.nc', 'liteVNA_110_-44.0.nc', 'liteVNA_110_-45.0.nc']\n",
    "\n",
    "    for f_name in file_list:\n",
    "        dataset = xr.open_dataset(f\"{resonator_data_folder}\\\\{f_name}\")\n",
    "        power = dataset.attrs[\"power\"]\n",
    "        attenuation = dataset.attrs[\"attenuation\"]\n",
    "        frequency = dataset.coords[\"frequency\"].values\n",
    "        data = dataset[\"s21\"].values\n",
    "        resonator.import_array(frequency, data[0]+1j*data[1], power-attenuation)\n",
    "    result = resonator.refined_analysis( result_folder )\n",
    "    # result = resonator.free_analysis( result_folder )\n",
    "\n",
    "    all_resonator_result.append( result )\n",
    "    \n",
    "    df_results = pd.concat(all_resonator_result)\n",
    "    df_results.Name = resonator_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_resonator_result = []\n",
    "folder_list = [d for d in os.listdir(preprocess_data_fd) if os.path.isdir(os.path.join(preprocess_data_fd, d))]\n",
    "\n",
    "fr = []\n",
    "qc = []\n",
    "for resonator_label in folder_list:\n",
    "    create_subfolder(output_fd,resonator_label)\n",
    "    result_folder = f\"{output_fd}\\\\{resonator_label}\"\n",
    "\n",
    "    # Plotting\n",
    "    df_powerQ_free = pd.read_csv( f\"{plot_data_fd}\\\\{resonator_label}\\\\free_result.csv\" )\n",
    "    plot_singleRes_powerQ_free(df_powerQ_free, cav_label=f\"{resonator_label}\", output_fd=result_folder)\n",
    "    plot_singleRes_powerloss_free(df_powerQ_free, cav_label=f\"{resonator_label}\", output_fd=result_folder)\n",
    "\n",
    "    df_powerQ_refined = pd.read_csv( f\"{plot_data_fd}\\\\{resonator_label}\\\\refined_result.csv\" )\n",
    "    plot_singleRes_powerQ_refined(df_powerQ_refined, cav_label=f\"{resonator_label}\", output_fd=result_folder)\n",
    "    plot_singleRes_powerloss_refined(df_powerQ_refined, cav_label=f\"{resonator_label}\", output_fd=result_folder)\n",
    "    fr.append(df_powerQ_refined[\"fr\"].values[-1])\n",
    "    qc.append(df_powerQ_refined[\"Qc_dia_corr_fixed\"].values[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After assignment each cavity, get foward analysis\n",
    "assignment = pd.read_json(r\"D:\\Data\\resonator\\ITRI378_scalinQ_coil_0904_wWB\\result\\assignment.json\")\n",
    "plot_multiRes_powerQ_free( output_fd, assignment, output_fd)\n",
    "plot_multiRes_powerQ_refined( output_fd, assignment, output_fd,((1e-2,1e9),(1e5,1e7)) )\n",
    "# ((3e-1,3e5),(1e5,5e6))\n",
    "pd.DataFrame({\"fr\":np.array(fr),\"Qc\":np.array(qc)}).to_csv( f\"{output_fd}/Qc.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定義擬合的公式\n",
    "def model_func(N_photons, delta_TLS, N_sat, alpha, delta_0):\n",
    "    return delta_TLS / np.sqrt(1 + (N_photons / N_sat)**alpha) + delta_0\n",
    "\n",
    "# 設定結果資料夾的路徑\n",
    "result_folder = r\"C:\\Users\\ASUS\\Documents\\python training\\舊檔案\\coil\\result\"  # 替換為你的result資料夾路徑\n",
    "\n",
    "# 建立一個空的DataFrame來存儲所有擬合結果\n",
    "fitting_results = pd.DataFrame(columns=['fr', 'delta_TLS', 'N_sat', 'alpha', 'delta_0'])\n",
    "\n",
    "# 遍歷result資料夾內的所有子資料夾\n",
    "for subdir, dirs, files in os.walk(result_folder):\n",
    "    for file in files:\n",
    "        if file == 'refined_result.csv':  # 檢查文件名稱\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            \n",
    "            # 讀取 CSV 文件\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # 提取數據\n",
    "            Qi_dia_corr = df['Qi_dia_corr'].values\n",
    "            photons = df['photons'].values\n",
    "            Qi_dia_corr_err = df['Qi_dia_corr_err'].values  # 提取誤差數據\n",
    "\n",
    "            # 根據 photons 排序\n",
    "            sorted_indices = np.argsort(photons)\n",
    "            photons_sorted = photons[sorted_indices]\n",
    "            Qi_dia_corr_sorted = Qi_dia_corr[sorted_indices]\n",
    "            Qi_dia_corr_err_sorted = Qi_dia_corr_err[sorted_indices]\n",
    "            \n",
    "            # 計算 delta_tot\n",
    "            delta_tot = 1 / Qi_dia_corr_sorted\n",
    "\n",
    "            # 設置初始猜測值\n",
    "            delta_0_initial = np.min(delta_tot)\n",
    "            delta_TLS_initial = np.max(delta_tot) - delta_0_initial\n",
    "            alpha_initial = 1.0  # 在 0 到 2 之間選擇一個值\n",
    "            N_sat_initial = 1e0  # 假設的初始值\n",
    "\n",
    "            # 提取 fr 欄位的第一個值\n",
    "            fr_value = df['fr'].iloc[0]\n",
    "\n",
    "            # 擬合數據，加權擬合使用誤差的倒數平方\n",
    "            weights = 1 / Qi_dia_corr_err_sorted**2\n",
    "            try:\n",
    "                popt, pcov = curve_fit(\n",
    "                    model_func,\n",
    "                    photons_sorted,\n",
    "                    delta_tot,\n",
    "                    p0=[delta_TLS_initial, N_sat_initial, alpha_initial, delta_0_initial],\n",
    "                    sigma=Qi_dia_corr_err_sorted,\n",
    "                    absolute_sigma=True\n",
    "                )\n",
    "                delta_TLS, N_sat, alpha, delta_0 = popt\n",
    "\n",
    "                # 保存擬合結果\n",
    "                new_row = pd.DataFrame({\n",
    "                    'fr': [fr_value],\n",
    "                    'delta_TLS': [delta_TLS],\n",
    "                    'N_sat': [N_sat],\n",
    "                    'alpha': [alpha],\n",
    "                    'delta_0': [delta_0]\n",
    "                })\n",
    "                fitting_results = pd.concat([fitting_results, new_row], ignore_index=True)\n",
    "                \n",
    "                # 可選: 畫出每個擬合結果\n",
    "                fitted_delta = model_func(photons_sorted, *popt)\n",
    "                plt.scatter(photons_sorted, delta_tot, label='Data')\n",
    "                plt.plot(photons_sorted, fitted_delta, color='red', label='Fit')\n",
    "                plt.xscale('log')\n",
    "                plt.yscale('log')\n",
    "                plt.xlabel('N_{photons}')\n",
    "                plt.ylabel('Δ_tot')\n",
    "                plt.title(f'Fitting Result for fr={fr_value}')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Fitting failed for {file_path}: {e}\")\n",
    "\n",
    "# 將擬合結果保存到一個新的 CSV 文件\n",
    "output_file = os.path.join(result_folder, 'fitting_results_new.csv')\n",
    "fitting_results.to_csv(output_file, index=False)\n",
    "print(f\"所有擬合結果已保存至 {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYQUM-server-offline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
